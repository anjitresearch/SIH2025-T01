ğŸš€ SIH Project Repository â€“ AI/ML-based Auto Evaluation of R&D Proposals

This repository contains the source code, data samples, and documentation for the Smart India Hackathon Problem Statement (SIH25180):
AI/ML-based Auto Evaluation of R&D Proposals for NaCCER, CMPDI Ranchi.

The system is designed to automatically evaluate R&D proposals based on:

âœ… Novelty detection against existing projects

âœ… Financial evaluation using funding guidelines

âœ… Impact scoring (technical feasibility, industry relevance)

âœ… Explainability of evaluation results

ğŸ“‚ Repository Structure
   SIH_Project_Repository/
â”‚â”€â”€ README.md                â†’ Project overview  
â”‚â”€â”€ requirements.txt         â†’ Python dependencies  
â”‚â”€â”€ data/  
â”‚   â”œâ”€â”€ raw/                 â†’ Sample input proposals (CSV)  
â”‚   â””â”€â”€ processed/           â†’ Cleaned proposals after preprocessing  
â”‚â”€â”€ src/  
â”‚   â”œâ”€â”€ preprocessing/       â†’ Data cleaning scripts  
â”‚   â”œâ”€â”€ models/              â†’ Novelty, financial, and scoring modules  
â”‚   â””â”€â”€ utils/               â†’ Explainability helpers  
â”‚â”€â”€ notebooks/               â†’ Jupyter notebooks for experiments  
â”‚â”€â”€ results/                 â†’ Sample output results (JSON)  
â”‚â”€â”€ docs/                    â†’ Documentation and project description  


âš™ï¸ Installation

Clone or unzip the repository:

git clone <repo-url>
cd SIH_Project_Repository


Install dependencies:

pip install -r requirements.txt


(Optional) Install NLP models:

python -m spacy download en_core_web_sm

â–¶ï¸ Usage
Preprocess proposals
from src.preprocessing.data_cleaning import clean_text

text = "Using AI to Improve Diagnosis Accuracy"
print(clean_text(text))

Run novelty detection
from src.models.novelty_detector import detect_novelty

result = detect_novelty("AI in healthcare for diagnosis support")
print(result)

Financial evaluation
from src.models.financial_evaluator import evaluate_financials

data = {"budget": 1000000, "expected_roi": 1.5}
print(evaluate_financials(data))

Scoring
from src.models.scoring import calculate_score

score = calculate_score(novelty=0.85, impact=0.9, roi=1.5)
print("Final Score:", score)

Explainability
from src.utils.explainability import explain_score

print(explain_score(0.92))

ğŸ“Š Example Output
{
  "proposal_id": 1,
  "novelty": 0.85,
  "roi": 1.5,
  "final_score": 0.92
}

ğŸŒŸ Key Features

Automated Evaluation â†’ Reduces manual effort and biases

Transparent Scoring â†’ Provides explainable AI-driven results

Financial Checks â†’ Ensures compliance with S&T guidelines

Scalable â†’ Can handle large volumes of proposals

ğŸ“– References

IEEE Xplore â€“ AI in Proposal Evaluation Systems

ResearchGate â€“ Machine Learning for Decision Support in R&D

Ministry of Coal (MoC) S&T Funding Guidelines
